---
title: "캡스톤 프로젝트"
description: |
  TBD
author:
  - name: 이은정
    url: https://2222Eunjeong.github.io/
    affiliation: 명지대학교
    affiliation_url: https://www.hanwhalife.com/index.jsp
  - name: 홍길동 
    affiliation: 명지대학교
    affiliation_url: https://www.hanwhalife.com/index.jsp    
date: "`r Sys.Date()`"
output: 
  distill::distill_article:
    toc: true
    toc_depth: 3  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      message = FALSE, 
                      warning = FALSE, 
                      collapse = FALSE,
                      fig.align = "center",
                      tidy.opts = list(width.cutoff = 70), 
                      tidy = TRUE)
knitr::opts_chunk$set(fig.width = 12, fig.height = 9)

library(shiny, warn.conflicts = FALSE)
library(dplyr, warn.conflicts = FALSE)
library(ggplot2, warn.conflicts = FALSE)


xaringanExtra :: use_panelset()
```

-- 
```{r, naverapi, echo=FALSE}
library(koscrap)

# Naver 뉴스 API 인증키

client_id <- "AZRTRw8iEbl9MXBBJq5p"
client_secret <- "vSA3or8ozk"

# 검색 키워드

keyword <- "월드컵"

n <- 1000
# 날짜 정렬 수집
news_worldcup_date <- search_naver(
  keyword, client_id = client_id, client_secret = client_secret,
  do_done = TRUE, max_record = n
)
```
# 유사도 정렬 수집
news_worldcup_sim <- search_naver(
  keyword, client_id = client_id, client_secret = client_secret, sort = "sim",
  do_done = TRUE, max_record = n
)

dim(news_worldcup_date)
dim(news_worldcup_sim)

head(news_worldcup_date)

tail(news_worldcup_sim)

# create UDF
create_wordcloud <- function(data, remove_n = 5, min_freq = 5, background = "white") {
  data %>% 
    filter(nchar(description_text) > 0) %>%   
    tidytext::unnest_tokens(noun, description_text, bitTA::morpho_mecab, type = "noun") %>% 
    group_by(noun) %>% 
    count() %>% 
    arrange(desc(n)) %>%     
    ungroup() %>%
    filter(n >= min_freq) %>% 
    filter(row_number() > remove_n) %>% 
    wordcloud2::wordcloud2(backgroundColor = background, 
                           fontFamily = "NanumSquare")
}

library(bitReport)

news_worldcup_date %>% 
  create_wordcloud(remove_n = 20, min_freq = 2)


news_worldcup_sim %>% 
  create_wordcloud(remove_n = 20, min_freq = 2)

persons <- c("벤투", "손흥민", "조규성", "이강인", "호날두", "메시")

persons %>% 
  purrr::map_int(
    function(x) {
      news_worldcup_sim %>% 
        filter(stringr::str_detect(description_text, x)) %>% 
        tally() %>% 
        pull()
    }
  )

persons <- c("벤투", "손흥민", "조규성", "이강인", "호날두", "메시")

persons %>% 
  purrr::map_dbl(
    function(x) {
      news_worldcup_sim %>% 
        filter(stringr::str_detect(description_text, x)) %>% 
        mutate(n_talk = stringr::str_count(description_text, x)) %>% 
        summarise(n_avg = mean(n_talk, na.rm = TRUE)) %>% 
        pull()
    }
  )

news_worldcup_sim <- news_worldcup_sim %>% 
  mutate(id = row_number())

library(tidyverse)
library(bitTA)
library(tidytext)
library(tm)

dtm_tf <- news_worldcup_sim %>% 
  unnest_noun_ngrams(term, description_text, n = 1, type = "noun2") %>% 
  filter(!str_detect(term, "[[a-zA-Z]]+")) %>%  
  count(id, term, sort = TRUE) %>% 
  cast_dtm(id, term, n)

tm::inspect(dtm_tf)

dtm_tfidf <- news_worldcup_sim %>% 
  unnest_noun_ngrams(term, description_text, n = 1, type = "noun2") %>% 
  filter(!str_detect(term, "[[a-zA-Z]]+")) %>%  
  count(id, term, sort = TRUE) %>% 
  cast_dtm(id, term, n, weighting = tm::weightTfIdf)

tm::inspect(dtm_tfidf)

persons <- c("벤투", "손흥민", "조규성", "이강인", "호날두", "메시")

persons %>% 
  purrr::map(
    function(x) tm::findAssocs(dtm_tf, terms = x, corlimit = 0.4)
  )

persons <- c("벤투", "손흥민", "조규성", "이강인", "호날두", "메시")

persons %>% 
  purrr::map(
    function(x) tm::findAssocs(dtm_tfidf, terms = x, corlimit = 0.4)
  )

dtm_bin_tf <- news_worldcup_sim %>% 
  unnest_noun_ngrams(term, description_text, n = 1, type = "noun2") %>% 
  filter(!str_detect(term, "[[a-zA-Z]]+")) %>%  
  count(id, term, sort = TRUE) %>% 
  cast_dtm(id, term, n, weighting = tm::weightBin)

stop_words <- dtm_bin_tf %>% 
  apply(2, sum) %>% 
  sort(decreasing = TRUE) %>% 
  "["(1:30) %>% 
  names()
stop_words

dtm_bin_tf <- news_worldcup_sim %>% 
  unnest_noun_ngrams(term, description_text, n = 1, type = "noun2") %>% 
  filter(!term %in% stop_words) %>% 
  filter(!str_detect(term, "[[a-zA-Z]]+|[[0-9]]+")) %>%  
  count(id, term, sort = TRUE) %>% 
  cast_dtm(id, term, n, weighting = tm::weightBin)

library("arules")

trans <- as(dtm_bin_tf %>% as.matrix(), "transactions")
trans

summary(trans)

rules <- apriori(trans, parameter = list(support = 0.05, conf = 0.6, target = "rules"))

summary(rules)

arules::inspect(rules[1:5])

library("arulesViz")

plot(rules)

rule2 <- sort(rules, by = "confidence")
inspect(head(rule2, n = 10))

plot(rules, method = "grouped")

plot(rules, method = "graph")

dim(dtm_bin_tf)

compact_bin <- tm::removeSparseTerms(dtm_bin_tf, sparse = 0.985) %>%
  as.matrix(compact_bin)

dim(compact_bin)

mat <- t(compact_bin)

dist_matrix <- dist(scale(mat))

fit <- hclust(dist_matrix, method = "ward.D")
fit

k <- 6

plot(fit)
cluster_list <- rect.hclust(fit, k = k)

k %>% 
  seq() %>% 
  purrr::map(
    function(x) {
      cluster_list[[x]]
    }
  )

mat <- compact_bin

dist_matrix <- dist(scale(mat))

fit <- hclust(dist_matrix, method = "ward.D")
fit


